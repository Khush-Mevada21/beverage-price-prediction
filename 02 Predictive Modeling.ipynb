{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc311eae-2848-4ef2-92a4-e8eb92f22c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1b32fe-e33f-4c9d-bff6-da47c47515c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataframe shape: (29956, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>zone</th>\n",
       "      <th>occupation</th>\n",
       "      <th>income_levels</th>\n",
       "      <th>consume_frequency(weekly)</th>\n",
       "      <th>current_brand</th>\n",
       "      <th>preferable_consumption_size</th>\n",
       "      <th>awareness_of_other_brands</th>\n",
       "      <th>reasons_for_choosing_brands</th>\n",
       "      <th>flavor_preference</th>\n",
       "      <th>purchase_channel</th>\n",
       "      <th>packaging_preference</th>\n",
       "      <th>health_concerns</th>\n",
       "      <th>typical_consumption_situations</th>\n",
       "      <th>price_range</th>\n",
       "      <th>age_group</th>\n",
       "      <th>cf_ab_score</th>\n",
       "      <th>zas_score</th>\n",
       "      <th>bsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R00001</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Newcomer</td>\n",
       "      <td>Medium (500 ml)</td>\n",
       "      <td>1</td>\n",
       "      <td>Price</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>Online</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Medium (Moderately health-conscious)</td>\n",
       "      <td>Active (eg. Sports, gym)</td>\n",
       "      <td>100-150</td>\n",
       "      <td>26-35</td>\n",
       "      <td>0.67</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R00002</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Established</td>\n",
       "      <td>Medium (500 ml)</td>\n",
       "      <td>2</td>\n",
       "      <td>Quality</td>\n",
       "      <td>Exotic</td>\n",
       "      <td>Retail Store</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Medium (Moderately health-conscious)</td>\n",
       "      <td>Social (eg. Parties)</td>\n",
       "      <td>200-250</td>\n",
       "      <td>46-55</td>\n",
       "      <td>0.60</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R00003</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Newcomer</td>\n",
       "      <td>Medium (500 ml)</td>\n",
       "      <td>2</td>\n",
       "      <td>Availability</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>Retail Store</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Medium (Moderately health-conscious)</td>\n",
       "      <td>Active (eg. Sports, gym)</td>\n",
       "      <td>200-250</td>\n",
       "      <td>36-45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R00004</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Newcomer</td>\n",
       "      <td>Medium (500 ml)</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand Reputation</td>\n",
       "      <td>Exotic</td>\n",
       "      <td>Online</td>\n",
       "      <td>Eco-Friendly</td>\n",
       "      <td>Low (Not very concerned)</td>\n",
       "      <td>Active (eg. Sports, gym)</td>\n",
       "      <td>150-200</td>\n",
       "      <td>26-35</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R00005</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Established</td>\n",
       "      <td>Medium (500 ml)</td>\n",
       "      <td>1</td>\n",
       "      <td>Availability</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>Online</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Medium (Moderately health-conscious)</td>\n",
       "      <td>Active (eg. Sports, gym)</td>\n",
       "      <td>50-100</td>\n",
       "      <td>18-25</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  respondent_id gender  zone            occupation  income_levels  \\\n",
       "0        R00001      M     3  Working Professional              1   \n",
       "1        R00002      F     4  Working Professional              5   \n",
       "2        R00003      F     1  Working Professional              5   \n",
       "3        R00004      F     3  Working Professional              3   \n",
       "4        R00005      M     4               Student              0   \n",
       "\n",
       "   consume_frequency(weekly) current_brand preferable_consumption_size  \\\n",
       "0                          2      Newcomer             Medium (500 ml)   \n",
       "1                          3   Established             Medium (500 ml)   \n",
       "2                          2      Newcomer             Medium (500 ml)   \n",
       "3                          3      Newcomer             Medium (500 ml)   \n",
       "4                          2   Established             Medium (500 ml)   \n",
       "\n",
       "   awareness_of_other_brands reasons_for_choosing_brands flavor_preference  \\\n",
       "0                          1                       Price       Traditional   \n",
       "1                          2                     Quality            Exotic   \n",
       "2                          2                Availability       Traditional   \n",
       "3                          1            Brand Reputation            Exotic   \n",
       "4                          1                Availability       Traditional   \n",
       "\n",
       "  purchase_channel packaging_preference                       health_concerns  \\\n",
       "0           Online               Simple  Medium (Moderately health-conscious)   \n",
       "1     Retail Store              Premium  Medium (Moderately health-conscious)   \n",
       "2     Retail Store              Premium  Medium (Moderately health-conscious)   \n",
       "3           Online         Eco-Friendly              Low (Not very concerned)   \n",
       "4           Online              Premium  Medium (Moderately health-conscious)   \n",
       "\n",
       "  typical_consumption_situations price_range age_group  cf_ab_score  \\\n",
       "0       Active (eg. Sports, gym)     100-150     26-35         0.67   \n",
       "1           Social (eg. Parties)     200-250     46-55         0.60   \n",
       "2       Active (eg. Sports, gym)     200-250     36-45         0.50   \n",
       "3       Active (eg. Sports, gym)     150-200     26-35         0.75   \n",
       "4       Active (eg. Sports, gym)      50-100     18-25         0.67   \n",
       "\n",
       "   zas_score  bsi  \n",
       "0          3    1  \n",
       "1         20    0  \n",
       "2          5    0  \n",
       "3          9    0  \n",
       "4          0    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CLEANED_FILE = 'cleaned_dataset.csv' \n",
    "df = pd.read_csv(CLEANED_FILE)\n",
    "print(\"Loaded dataframe shape:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c114b7-8fba-40bf-89e0-7fc5e1fe5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"price_range\"\n",
    "if TARGET not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET}' not found in dataframe. Please ensure '{CLEANED_FILE}' contains '{TARGET}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31296456-6045-4d58-bca3-14bba798b2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['respondent_id', 'gender', 'zone', 'occupation', 'income_levels', 'consume_frequency(weekly)', 'current_brand', 'preferable_consumption_size', 'awareness_of_other_brands', 'reasons_for_choosing_brands', 'flavor_preference', 'purchase_channel', 'packaging_preference', 'health_concerns', 'typical_consumption_situations', 'price_range', 'age_group', 'cf_ab_score', 'zas_score', 'bsi']\n",
      "\n",
      "Null counts:\n",
      "respondent_id                     0\n",
      "gender                            0\n",
      "zone                              0\n",
      "occupation                        0\n",
      "income_levels                     0\n",
      "consume_frequency(weekly)         0\n",
      "current_brand                     0\n",
      "preferable_consumption_size       0\n",
      "awareness_of_other_brands         0\n",
      "reasons_for_choosing_brands       0\n",
      "flavor_preference                 0\n",
      "purchase_channel                  0\n",
      "packaging_preference              0\n",
      "health_concerns                   0\n",
      "typical_consumption_situations    0\n",
      "price_range                       0\n",
      "age_group                         0\n",
      "cf_ab_score                       0\n",
      "zas_score                         0\n",
      "bsi                               0\n",
      "dtype: int64\n",
      "\n",
      "Target value counts:\n",
      "price_range\n",
      "200-250    9711\n",
      "150-200    8797\n",
      "100-150    7793\n",
      "50-100     3655\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nNull counts:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nTarget value counts:\")\n",
    "print(df[TARGET].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d4a0b6-f793-4217-b750-aaadef3a3704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns count: 18\n"
     ]
    }
   ],
   "source": [
    "if \"respondent_id\" in df.columns:\n",
    "    df = df.drop(columns=[\"respondent_id\"])\n",
    "\n",
    "X = df.drop(columns=[TARGET]).copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "print(\"Feature columns count:\", X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ecf1e1-00be-4331-b03e-b47ad3213d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (22467, 18) Test shape: (7489, 18)\n"
     ]
    }
   ],
   "source": [
    "stratify_arg = y if (y.nunique() > 1 and y.dtype != \"float\") else None\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42, stratify=y\n",
    "    )\n",
    "except Exception:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42, stratify=None\n",
    "    )\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b349a293-aa20-42ed-bc30-83d6c6d1c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode_cols_requested = [\n",
    "    \"age_group\",\n",
    "    \"income_levels\",\n",
    "    \"health_concerns\",\n",
    "    \"consume_frequency(weekly)\",\n",
    "    \"preferable_consumption_size\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e6248d-506c-41d4-ba0e-2a1f036442bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label-encode columns (present): ['age_group', 'income_levels', 'health_concerns', 'consume_frequency(weekly)', 'preferable_consumption_size']\n",
      "One-hot columns (detected): ['gender', 'occupation', 'current_brand', 'reasons_for_choosing_brands', 'flavor_preference', 'purchase_channel', 'packaging_preference', 'typical_consumption_situations']\n"
     ]
    }
   ],
   "source": [
    "label_encode_cols = [c for c in label_encode_cols_requested if c in X_train.columns]\n",
    "cat_cols_all = list(X_train.select_dtypes(include=[\"object\", \"category\"]).columns)\n",
    "onehot_cols = [c for c in cat_cols_all if c not in label_encode_cols]\n",
    "\n",
    "print(\"Label-encode columns (present):\", label_encode_cols)\n",
    "print(\"One-hot columns (detected):\", onehot_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5214419-fdbb-4a01-ba1d-a84c827a129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target classes: ['100-150', '150-200', '200-250', '50-100']\n",
      "Feature label encoding complete.\n"
     ]
    }
   ],
   "source": [
    "le_target = LabelEncoder()\n",
    "y_train_enc = le_target.fit_transform(y_train.astype(str))\n",
    "y_test_enc = le_target.transform(y_test.astype(str))\n",
    "target_classes = le_target.classes_\n",
    "print(\"Target classes:\", list(target_classes))\n",
    "\n",
    "# Feature label encoders \n",
    "label_encoders = {}\n",
    "for col in label_encode_cols:\n",
    "    X_train[col] = X_train[col].fillna(\"___MISSING___\").astype(str)\n",
    "    X_test[col] = X_test[col].fillna(\"___MISSING___\").astype(str)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X_train[col])\n",
    "    X_train[col] = le.transform(X_train[col])\n",
    "    test_vals = set(X_test[col].unique())\n",
    "    unseen = [v for v in test_vals if v not in set(le.classes_)]\n",
    "    if unseen:\n",
    "        union = list(le.classes_) + [\"___UNSEEN___\"]\n",
    "        le2 = LabelEncoder()\n",
    "        le2.fit(union)\n",
    "        X_train[col] = le2.transform(X_train[col].astype(str))\n",
    "        X_test[col] = X_test[col].astype(str).map(lambda v: v if v in union else \"___UNSEEN___\")\n",
    "        X_test[col] = le2.transform(X_test[col])\n",
    "        label_encoders[col] = le2\n",
    "    else:\n",
    "        X_test[col] = le.transform(X_test[col])\n",
    "        label_encoders[col] = le\n",
    "print(\"Feature label encoding complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e70af37-f1cb-4667-8a86-92dc90aa4e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoding shapes - Train: (22467, 32) Test: (7489, 32)\n"
     ]
    }
   ],
   "source": [
    "if len(onehot_cols) > 0:\n",
    "    for c in onehot_cols:\n",
    "        X_train[c] = X_train[c].fillna(\"___MISSING___\").astype(str)\n",
    "        X_test[c] = X_test[c].fillna(\"___MISSING___\").astype(str)\n",
    "\n",
    "    X_train_ohe = pd.get_dummies(X_train, columns=onehot_cols, drop_first=False)\n",
    "    X_test_ohe = pd.get_dummies(X_test, columns=onehot_cols, drop_first=False)\n",
    "\n",
    "    X_train_ohe, X_test_ohe = X_train_ohe.align(X_test_ohe, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "    X_train_ohe = X_train_ohe.fillna(0)\n",
    "    X_test_ohe = X_test_ohe.fillna(0)\n",
    "else:\n",
    "    X_train_ohe = X_train.copy()\n",
    "    X_test_ohe = X_test.copy()\n",
    "\n",
    "print(\"After encoding shapes - Train:\", X_train_ohe.shape, \"Test:\", X_test_ohe.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b41623-54a1-4e4d-b7fd-3885281caae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric imputation & scaling complete. Final feature count: 10\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = X_train_ohe.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if len(numeric_cols) == 0:\n",
    "    raise ValueError(\"No numeric columns found after encoding. Please check the data and encoding steps.\")\n",
    "\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num = imp.fit_transform(X_train_ohe[numeric_cols])\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "\n",
    "X_test_num = imp.transform(X_test_ohe[numeric_cols])\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "\n",
    "X_train_final = pd.DataFrame(X_train_num, columns=numeric_cols, index=X_train_ohe.index)\n",
    "X_test_final = pd.DataFrame(X_test_num, columns=numeric_cols, index=X_test_ohe.index)\n",
    "\n",
    "print(\"Numeric imputation & scaling complete. Final feature count:\", X_train_final.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1e9968-730e-42e6-b4a7-a68f031cc1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr = X_train_final.values\n",
    "X_test_arr = X_test_final.values\n",
    "y_train_arr = y_train_enc\n",
    "y_test_arr = y_test_enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1d93219-6140-43e5-8881-895f1614e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Support Vector Machine\": SVC(random_state=42),         \n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e83767-25d4-47c2-aedf-4112f10649f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "def train_and_evaluate(name, model, Xtr, Xte, ytr, yte, target_names):\n",
    "    t0 = time()\n",
    "    model.fit(Xtr, ytr)\n",
    "    tt = time() - t0\n",
    "    preds = model.predict(Xte)\n",
    "    acc = accuracy_score(yte, preds)\n",
    "    report = classification_report(yte, preds, target_names=target_names, zero_division=0)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Training time (s): {tt:.3f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification report|:\")\n",
    "    print(report)\n",
    "    results[name] = {\"model\": model, \"accuracy\": acc, \"report\": report}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0775c77-1216-4115-a8a5-3dc3fbd1c471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Training time (s): 0.014\n",
      "Accuracy: 0.6321\n",
      "Classification report|:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.53      0.35      0.42      1948\n",
      "     150-200       0.59      0.58      0.58      2199\n",
      "     200-250       0.84      0.81      0.82      2428\n",
      "      50-100       0.48      0.89      0.63       914\n",
      "\n",
      "    accuracy                           0.63      7489\n",
      "   macro avg       0.61      0.66      0.61      7489\n",
      "weighted avg       0.64      0.63      0.62      7489\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Model: Logistic Regression\n",
      "Training time (s): 0.409\n",
      "Accuracy: 0.7642\n",
      "Classification report|:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.71      0.72      0.71      1948\n",
      "     150-200       0.70      0.70      0.70      2199\n",
      "     200-250       0.87      0.87      0.87      2428\n",
      "      50-100       0.78      0.73      0.75       914\n",
      "\n",
      "    accuracy                           0.76      7489\n",
      "   macro avg       0.76      0.76      0.76      7489\n",
      "weighted avg       0.76      0.76      0.76      7489\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Model: Support Vector Machine\n",
      "Training time (s): 17.086\n",
      "Accuracy: 0.8355\n",
      "Classification report|:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.81      0.80      0.80      1948\n",
      "     150-200       0.78      0.81      0.79      2199\n",
      "     200-250       0.91      0.89      0.90      2428\n",
      "      50-100       0.85      0.82      0.84       914\n",
      "\n",
      "    accuracy                           0.84      7489\n",
      "   macro avg       0.84      0.83      0.83      7489\n",
      "weighted avg       0.84      0.84      0.84      7489\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Model: Random Forest\n",
      "Training time (s): 5.579\n",
      "Accuracy: 0.8293\n",
      "Classification report|:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.81      0.79      0.80      1948\n",
      "     150-200       0.78      0.77      0.77      2199\n",
      "     200-250       0.89      0.90      0.90      2428\n",
      "      50-100       0.84      0.85      0.85       914\n",
      "\n",
      "    accuracy                           0.83      7489\n",
      "   macro avg       0.83      0.83      0.83      7489\n",
      "weighted avg       0.83      0.83      0.83      7489\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KHUSH\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:199: UserWarning: [16:19:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Model: XGBoost\n",
      "Training time (s): 4.233\n",
      "Accuracy: 0.8495\n",
      "Classification report|:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.82      0.81      0.82      1948\n",
      "     150-200       0.80      0.81      0.81      2199\n",
      "     200-250       0.91      0.91      0.91      2428\n",
      "      50-100       0.85      0.86      0.86       914\n",
      "\n",
      "    accuracy                           0.85      7489\n",
      "   macro avg       0.85      0.85      0.85      7489\n",
      "weighted avg       0.85      0.85      0.85      7489\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60\n",
      "[LightGBM] [Info] Number of data points in the train set: 22467, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.346461\n",
      "[LightGBM] [Info] Start training from score -1.225281\n",
      "[LightGBM] [Info] Start training from score -1.126505\n",
      "[LightGBM] [Info] Start training from score -2.103725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KHUSH\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\KHUSH\\AppData\\Roaming\\Python\\Python313\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"C:\\Program Files\\Python313\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python313\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python313\\Lib\\subprocess.py\", line 1551, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Model: LightGBM\n",
      "Training time (s): 7.475\n",
      "Accuracy: 0.8502\n",
      "Classification report|:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.82      0.81      0.82      1948\n",
      "     150-200       0.80      0.81      0.81      2199\n",
      "     200-250       0.92      0.91      0.91      2428\n",
      "      50-100       0.84      0.87      0.86       914\n",
      "\n",
      "    accuracy                           0.85      7489\n",
      "   macro avg       0.85      0.85      0.85      7489\n",
      "weighted avg       0.85      0.85      0.85      7489\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KHUSH\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    try:\n",
    "        train_and_evaluate(name, model, X_train_arr, X_test_arr, y_train_arr, y_test_arr, target_classes)\n",
    "    except Exception as e:\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(f\"ERROR training/evaluating {name}: {e}\")\n",
    "        print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ed9c790-c2f6-4ed8-ba2f-d59d7642aaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model performance summary (sorted by accuracy):\n",
      "LightGBM                  -> Accuracy: 0.8502\n",
      "XGBoost                   -> Accuracy: 0.8495\n",
      "Support Vector Machine    -> Accuracy: 0.8355\n",
      "Random Forest             -> Accuracy: 0.8293\n",
      "Logistic Regression       -> Accuracy: 0.7642\n",
      "Gaussian Naive Bayes      -> Accuracy: 0.6321\n"
     ]
    }
   ],
   "source": [
    "if results:\n",
    "    summary = sorted([(name, info[\"accuracy\"]) for name, info in results.items()], key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nModel performance summary (sorted by accuracy):\")\n",
    "    for name, acc in summary:\n",
    "        print(f\"{name:25s} -> Accuracy: {acc:.4f}\")\n",
    "else:\n",
    "    print(\"No successful model runs to summarize.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd0d6f2-72d7-4efd-a477-23f71c5fc160",
   "metadata": {},
   "source": [
    "## ML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e5283c4-bee4-4af0-9e00-12dec015b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0b53ea1-9646-49f4-83d8-4fafb5173aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow, os\n",
    "\n",
    "# USERNAME = \" \"\n",
    "# REPO = \" \"\n",
    "# TOKEN = \" \"   \n",
    "\n",
    "# os.environ[\"MLFLOW_TRACKING_USERNAME\"] = USERNAME\n",
    "# os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = TOKEN\n",
    "\n",
    "# EXPERIMENT_NAME = \"Beverage Price Prediction\"\n",
    "# mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# print(\"Tracking URI :\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34e8d805-b03b-4a87-81b8-1ef7fb6ad203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KHUSH\\AppData\\Roaming\\Python\\Python313\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"Beverage Price Prediction\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "723af2b3-07c9-4ed2-b14e-978567f299c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_mlflow(model_name, model_obj, accuracy, report, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Logs model, parameters, metrics, and classification report to MLflow (DagsHub compatible).\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        params = getattr(model_obj, \"get_params\", lambda: {})()\n",
    "        if isinstance(params, dict):\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        lines = report.strip().split(\"\\n\")\n",
    "        for line in lines[2:-3]: \n",
    "            parts = [x for x in line.split() if x]\n",
    "            if len(parts) >= 4:\n",
    "                label, precision, recall, f1, support = parts[0:5]\n",
    "                try:\n",
    "                    mlflow.log_metric(f\"{label}_precision\", float(precision))\n",
    "                    mlflow.log_metric(f\"{label}_recall\", float(recall))\n",
    "                    mlflow.log_metric(f\"{label}_f1\", float(f1))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        import joblib\n",
    "        joblib.dump(model_obj, f\"{model_name}_model.pkl\")\n",
    "        mlflow.log_artifact(f\"{model_name}_model.pkl\")\n",
    "\n",
    "        # Log small sample of training data\n",
    "        sample = pd.DataFrame(X_train[:5])\n",
    "        sample['target'] = y_train[:5]\n",
    "        sample.to_csv(f\"{model_name}_train_sample.csv\", index=False)\n",
    "        mlflow.log_artifact(f\"{model_name}_train_sample.csv\")\n",
    "\n",
    "        print(f\"Logged {model_name} to MLflow (DagsHub).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba7c49d6-dc07-40f7-a647-e0d6f4b95e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mlflow.start_run(run_name=\"dagshub_test_run\"):\n",
    "#     mlflow.log_param(\"test_param\", 1)\n",
    "#     mlflow.log_metric(\"test_metric\", 0.99)\n",
    "\n",
    "# print(\"âœ… DagsHub connection successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3141eae4-a5e1-49df-b999-87072d3370a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tempfile\n",
    "\n",
    "# with tempfile.NamedTemporaryFile(\"w\", delete=False, suffix=\".txt\") as tmp:\n",
    "#     tmp.write(\"This is a test artifact.\")\n",
    "#     temp_file_path = tmp.name\n",
    "\n",
    "# with mlflow.start_run(run_name=\"dagshub_test_run\"):\n",
    "#     mlflow.log_param(\"test_param\", 1)\n",
    "#     mlflow.log_metric(\"test_metric\", 0.99)\n",
    "#     mlflow.log_artifact(temp_file_path)\n",
    "\n",
    "# print(\"âœ… DagsHub connection + artifact upload successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95a6accc-ca58-4d5d-bc45-aabd2617151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Training Gaussian Naive Bayes...\n",
      "================================================================================\n",
      "Accuracy: 0.6321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.53      0.35      0.42      1948\n",
      "     150-200       0.59      0.58      0.58      2199\n",
      "     200-250       0.84      0.81      0.82      2428\n",
      "      50-100       0.48      0.89      0.63       914\n",
      "\n",
      "    accuracy                           0.63      7489\n",
      "   macro avg       0.61      0.66      0.61      7489\n",
      "weighted avg       0.64      0.63      0.62      7489\n",
      "\n",
      "Logged Gaussian Naive Bayes to MLflow (DagsHub).\n",
      "ðŸƒ View run Gaussian Naive Bayes at: http://127.0.0.1:5000/#/experiments/977387589067566005/runs/9ddd6729691c4c2699d2c49efb7446db\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/977387589067566005\n",
      "\n",
      "================================================================================\n",
      "Training Logistic Regression...\n",
      "================================================================================\n",
      "Accuracy: 0.7642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.71      0.72      0.71      1948\n",
      "     150-200       0.70      0.70      0.70      2199\n",
      "     200-250       0.87      0.87      0.87      2428\n",
      "      50-100       0.78      0.73      0.75       914\n",
      "\n",
      "    accuracy                           0.76      7489\n",
      "   macro avg       0.76      0.76      0.76      7489\n",
      "weighted avg       0.76      0.76      0.76      7489\n",
      "\n",
      "Logged Logistic Regression to MLflow (DagsHub).\n",
      "ðŸƒ View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/977387589067566005/runs/e4d207546b7846f095a375617026c28f\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/977387589067566005\n",
      "\n",
      "================================================================================\n",
      "Training Support Vector Machine...\n",
      "================================================================================\n",
      "Accuracy: 0.8355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.81      0.80      0.80      1948\n",
      "     150-200       0.78      0.81      0.79      2199\n",
      "     200-250       0.91      0.89      0.90      2428\n",
      "      50-100       0.85      0.82      0.84       914\n",
      "\n",
      "    accuracy                           0.84      7489\n",
      "   macro avg       0.84      0.83      0.83      7489\n",
      "weighted avg       0.84      0.84      0.84      7489\n",
      "\n",
      "Logged Support Vector Machine to MLflow (DagsHub).\n",
      "ðŸƒ View run Support Vector Machine at: http://127.0.0.1:5000/#/experiments/977387589067566005/runs/b205e7fc411b47fe8cad94e40e7df158\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/977387589067566005\n",
      "\n",
      "================================================================================\n",
      "Training Random Forest...\n",
      "================================================================================\n",
      "Accuracy: 0.8293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.81      0.79      0.80      1948\n",
      "     150-200       0.78      0.77      0.77      2199\n",
      "     200-250       0.89      0.90      0.90      2428\n",
      "      50-100       0.84      0.85      0.85       914\n",
      "\n",
      "    accuracy                           0.83      7489\n",
      "   macro avg       0.83      0.83      0.83      7489\n",
      "weighted avg       0.83      0.83      0.83      7489\n",
      "\n",
      "Logged Random Forest to MLflow (DagsHub).\n",
      "ðŸƒ View run Random Forest at: http://127.0.0.1:5000/#/experiments/977387589067566005/runs/1813198fe025476ea9b2a7fddfe9e844\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/977387589067566005\n",
      "\n",
      "================================================================================\n",
      "Training XGBoost...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KHUSH\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:199: UserWarning: [16:20:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.82      0.81      0.82      1948\n",
      "     150-200       0.80      0.81      0.81      2199\n",
      "     200-250       0.91      0.91      0.91      2428\n",
      "      50-100       0.85      0.86      0.86       914\n",
      "\n",
      "    accuracy                           0.85      7489\n",
      "   macro avg       0.85      0.85      0.85      7489\n",
      "weighted avg       0.85      0.85      0.85      7489\n",
      "\n",
      "Logged XGBoost to MLflow (DagsHub).\n",
      "ðŸƒ View run XGBoost at: http://127.0.0.1:5000/#/experiments/977387589067566005/runs/a2833b2bca344a8a8c4e90ffca61b8f6\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/977387589067566005\n",
      "\n",
      "================================================================================\n",
      "Training LightGBM...\n",
      "================================================================================\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60\n",
      "[LightGBM] [Info] Number of data points in the train set: 22467, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.346461\n",
      "[LightGBM] [Info] Start training from score -1.225281\n",
      "[LightGBM] [Info] Start training from score -1.126505\n",
      "[LightGBM] [Info] Start training from score -2.103725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KHUSH\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     100-150       0.82      0.81      0.82      1948\n",
      "     150-200       0.80      0.81      0.81      2199\n",
      "     200-250       0.92      0.91      0.91      2428\n",
      "      50-100       0.84      0.87      0.86       914\n",
      "\n",
      "    accuracy                           0.85      7489\n",
      "   macro avg       0.85      0.85      0.85      7489\n",
      "weighted avg       0.85      0.85      0.85      7489\n",
      "\n",
      "Logged LightGBM to MLflow (DagsHub).\n",
      "ðŸƒ View run LightGBM at: http://127.0.0.1:5000/#/experiments/977387589067566005/runs/123ff85e17414905bc87577212b8d7fa\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/977387589067566005\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        print(f\"\\n{'='*80}\\nTraining {name}...\\n{'='*80}\")\n",
    "        t0 = time()\n",
    "        model.fit(X_train_arr, y_train_arr)\n",
    "        duration = time() - t0\n",
    "        preds = model.predict(X_test_arr)\n",
    "        \n",
    "        acc = accuracy_score(y_test_arr, preds)\n",
    "        report = classification_report(y_test_arr, preds, target_names=target_classes, zero_division=0)\n",
    "        \n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(report)\n",
    "        \n",
    "        results[name] = {\"model\": model, \"accuracy\": acc, \"report\": report, \"train_time\": duration}\n",
    "        \n",
    "        log_to_mlflow(name, model, acc, report, X_train_arr, y_train_arr)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "959653cb-0b26-427a-bd18-980ebe7fbf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model Accuracy Summary:\n",
      "LightGBM                  -> 0.8502\n",
      "XGBoost                   -> 0.8495\n",
      "Support Vector Machine    -> 0.8355\n",
      "Random Forest             -> 0.8293\n",
      "Logistic Regression       -> 0.7642\n",
      "Gaussian Naive Bayes      -> 0.6321\n",
      "\n",
      "All runs are logged to MLflow experiment: Beverage Price Prediction\n"
     ]
    }
   ],
   "source": [
    "summary = sorted([(n, r[\"accuracy\"]) for n, r in results.items()], key=lambda x: x[1], reverse=True)\n",
    "print(\"\\n\\nModel Accuracy Summary:\")\n",
    "for n, a in summary:\n",
    "    print(f\"{n:25s} -> {a:.4f}\")\n",
    "\n",
    "print(\"\\nAll runs are logged to MLflow experiment:\", EXPERIMENT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01433d1c-0677-4df0-a838-b1ac5799ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: LightGBM\n",
      "Accuracy: 0.8502\n"
     ]
    }
   ],
   "source": [
    "# Find the model with the highest accuracy\n",
    "best_model_name = max(results, key=lambda x: results[x][\"accuracy\"])\n",
    "best_model_info = results[best_model_name]\n",
    "best_model = best_model_info[\"model\"]\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_model_info['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "682325a2-7e42-4dec-bed7-e6982926d9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Best model saved as: best_model_LightGBM.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model, f\"best_model_{best_model_name}.pkl\")\n",
    "print(f\"ðŸ’¾ Best model saved as: best_model_{best_model_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0224698d-cc12-494a-bf79-ddfd3b91190a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_target.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the list of final features (columns in X_train_final)\n",
    "trained_features = list(X_train_final.columns)\n",
    "joblib.dump(trained_features, \"trained_feature_columns.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c885161-b4c1-4332-b93e-ed666492c9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scaler\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38d5c18e-323c-409b-87ed-73a62df53ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_target.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save target label encoder\n",
    "joblib.dump(le_target, \"label_encoder_target.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b99f7e-d38c-4098-8b49-c98cb06ce154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
